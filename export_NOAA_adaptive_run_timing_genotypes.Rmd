---
title: "Export Genotypes for 9 Adaptive Run Timing Loci to NOAA"
subtitle: "Filtered for Plates Not Needing QC Crosschecks"
author: "Kyle Shedd"
date: "Started: 2025-07-24, last opened: `r Sys.Date()`"
output:
  html_notebook:
    theme: united
    toc: yes
    toc_float: true
editor_options: 
  chunk_output_type: inline
---

# Setup

```{r setup, message=FALSE, results='hide'}
rm(list = ls(all.names = TRUE))

if(!require("pacman")) install.packages("pacman"); library(pacman)

pacman::p_load(
  tidyverse,
  scales,
  janitor,
  GCLr,
  coin
)

knitr::opts_chunk$set(fig.width = 10)
knitr::opts_chunk$set(echo = TRUE)

.username = readLines("~/usr_pw.txt", n = 1)  # LOKI username
.password = readLines("~/usr_pw.txt" , n = 2)[[2]]  # LOKI password
```

# Objective

The purpose of this notebook is to provide Wes Larson (NOAA ABL) with adaptive run timing genotypes (9 loci) for AHRP chum samples. Filter out plates undergoing QC crosschecks due to poor genotyping success. Wes is interested in representation across years, less across multiple streams. He wants to see how the patterns hold up over time.

## Steps

  * import all existing genotypes for CM064-CM070
  * filter out untrustworthy plates that need QC cross checks
  * standard GT-seq genotype QA (missing, heterozygosity, duplicate)
  * join sample date and spawning state <"../OceanAK/AHRP Salmon Biological Data 20240105_122404.368459_with_spawning_state.csv">
  * filter for 9 adaptive run timing loci
  * export genotypes with date/spawning state

# Background

An adaptive marker panel associated with run timing variation in chum salmon was developed by NOAA ABL and used to genotype two plates of samples from the ADFG Alaska Hatchery Research Program (AHRP) study being conducted within SE Alaska. AHRP samples (Fish Creek - Douglas Island 2023 + Prospect Creek 2017/2018) were genotyped in August 2024 for 20 single nucleotide polymorphisms and weighted linear regressions were performed to assess the association of different SNPs with run timing (date of collection). The chum salmon adaptive marker panel contains 20 loci spread among 5 chromosomes and was developed from variation detected between Yukon River summer (Gisasa River) and fall (Pelly River) run chum salmon with low coverage whole genome sequencing.These populations spawn approximately two months and over 1500 river km apart. NOAA targeted the major peaks in differentiation with particular interest in markers within the genes leucine rich repeat containing nine (LRRC9; LG35) and estrogen receptor Î² (ESRB; LG29) as they were associated with return timing in other salmonid species. Eight SNPs (four on LG29 and four on LG35) appear to be associated with run timing within these collections. The strength of association for AHRP samples appears to vary by population. No markers on LGs 5, 23 or 15 appear to have a strong association with run timing within these collections. Overall, the results from LG29 and LG35 are promising and variation in these SNPs should be surveyed for a larger collection of samples.

A total of 9 adaptive, run timing loci were added to the AHRP SEAK Chum parentage panel: 

  * OkeV2_LG23_10546237
  * OkeV2_LG29_25450752
  * OkeV2_LG29_25455833
  * OkeV2_LG29_25483595
  * OkeV2_LG29_25515161
  * OkeV2_LG35_28078867
  * OkeV2_LG35_28128687
  * OkeV2_LG35_28165076
  * OkeV2_LG35_28167172

All AHRP Chum samples from Fish Creek - Douglas Island, Prospect Creek, Admiralty Creek, and Sawmill Creek were genotyped for the parentage panel at the ADF&G Gene Conservation Laboratory (GCL) in Winter/Spring 2025. Due to poor tissue quality, there was a high proportion of samples that failed to genotype and/or appear to be contaminated (high heterozygosity), resulting in low QC power for several plates. QC crosschecks are currently underway at the GCL in July 2025, however, Wes wants whatever genotypes we have on hand now so will just filter out those plates.

# Import Data

## *LocusControl*

Create `objects`, create *LocusControl* for `Chum_AHRP_257_v1.3.0.`
```{r LocusControl, eval=FALSE}
fs::dir_create("objects")
GCLr::create_locuscontrol(markersuite = "Chum_AHRP_257_v1.3.0",
                          username = .username,
                          password = .password)
GCLr::save_objects(objects = "LocusControl", path = "objects")
```

Hrmm, only 251 loci. Confirm that these are the same loci run in the most recent AHRP Chum project CM069
```{r, eval=FALSE}
probe_loci_CM069 <- readr::read_tsv(
  file = "V:/Lab/Genotyping/SNP Projects/Chum/Project CM069 AHRP Parentage/Genotype Data Files/set2rr_CM069_outputs/probes.txt", 
  show_col_types = FALSE) %>%
  dplyr::distinct(`#Locus_ID`) %>%
  dplyr::pull()

all.equal(probe_loci_CM069, LocusControl$locusnames)
```

Yes, all are the same.
```{r, eval=FALSE}
loci251 <- LocusControl$locusnames
GCLr::save_objects(objects = "loci251", path = "objects")
```

## Genotypes

Read in genotypes by projec to get sillyvec.
```{r, eval=FALSE}
rm(LocusControl)
# GCLr::loki2r_proj(project_name = paste0("CM0", 64:70), username = .username, password = .password)  # comment out to avoid re-running
```

What collections?
```{r, eval=FALSE}
(sillyvec <- sort(project_sillys))
```

Subset `sillyvec` to remove alevin collection
```{r, eval=FALSE}
(sillyvec <- grep(pattern = "a", x = sillyvec, ignore.case = FALSE, value = TRUE, invert = TRUE))
```

Wipe out `.gcl` objects and re-read in using `loki2r`.
```{r, eval=FALSE}
GCLr::save_objects(objects = "sillyvec", path = "objects")

rm(list = objects(pattern = ".gcl"))
rm(LocusControl)
```

Read in genotypes.
```{r eval=FALSE}
GCLr::load_objects(path = "objects", pattern = "LocusControl")

GCLr::loki2r(sillyvec = sillyvec,
             username = .username,
             password = .password, 
             test_type = "GTSNP")
```

Only took 5.39 minutes to read everything in at the office!

Save raw genotypes (useful for working offsite and off VPN).
```{r eval=FALSE}
fs::dir_create("data/genotypes")
fs::dir_create("data/genotypes/raw")
# GCLr::save_sillys(sillyvec = sillyvec, path = "data/genotypes/raw", rds = TRUE)  # hide so you don't overwrite on accident!
```


### Re-load

Re-load, if necessary
```{r}
GCLr::load_objects(path = "objects")
GCLr::load_sillys(sillyvec = sillyvec, path = "data/genotypes/raw", rds = TRUE)
```

## Metadata

Read in paired metadata from Salmon Biological Fact and Stream Specimens, format similar to `pws_pink_ped_dat`. **NOTE** I'm doing this in a bit of a hurry, so make sure to proof read carefully if recycling this code!
```{r}
(metadata <- readr::read_csv(file = "../OceanAK/AHRP Salmon Biological Data 20240105_122404.368459_with_spawning_state.csv"))
```

Modify
```{r}
(
  metadata <- metadata %>% 
    dplyr::select(-dplyr::contains("target")) %>% 
    dplyr::select(-dplyr::contains("determination")) %>% 
    dplyr::rename(date = sample_date,
                  length = length_mm,
                  silly = silly_code) %>% 
    tidyr::unite(col = "sample", dna_tray_code:dna_tray_well_code, sep = "_", remove = FALSE) %>% 
    tidyr::unite(col = "silly_source", c(silly, fish_id), sep = "_", remove = FALSE) %>% 
    dplyr::mutate(franz_id = stringr::str_c(stringr::str_sub(silly, 1, 2),  # 1st letter of species name, 1st letter of stream name
                                            stringr::str_sub(silly, -2, -1),  # 2 digit sample year
                                            "_",
                                            stringr::str_pad(fish_id, width = 5, pad = "0", side = "left")),  # 5 digit fishid using padded zeros up front)
                  year = lubridate::year(date),
                  stream = stringr::str_remove(string = location_code, pattern = " Creek"),
                  DOY = lubridate::yday(date),  # day of year
                  sex = dplyr::case_when(
                    sex == "M" ~ "Male",
                    sex == "F" ~ "Female",
                    sex == "U" ~ NA_character_,
                    is.na(sex) ~ NA_character_),
                  origin = dplyr::case_when(
                    otolith_mark_present == "NO" ~ "Natural",
                    otolith_mark_present == "YES" ~ "Hatchery"
                  ),  # add origin variable
                  origin = base::factor(origin, levels = c("Natural", "Hatchery")),  # make factor to ensure hatchery != red
                  spawning_state = dplyr::case_when(
                    spawning_state == "Unknown" ~ NA_character_,
                    TRUE ~ spawning_state
                  )  # force Unknown to NA
    ) %>%  
    dplyr::select(
      franz_id,  # unique identifier for FRANz (e.g. PE16_00001, species, stream, year, GCL fish_id)
      sample,  # ultimate data key for AHRP, DWP barcode + DWP position
      silly_source,  # unique identifier for LOKI (GCL database)
      stream,  # 5 pedigree streams
      year,  # sample year (aka death year for FRANz)
      origin,  # hatchery or wild
      # hatchery,  # which hatchery
      sex,  # male, female, unknown
      date,  # sample date
      DOY,  # day of year (aka julian sample date)
      length,  # mideye to hypural plate length in mm
      # intertidal,  # sampling location above or below intertidal
      # distance_mouth,  # riverdist approximate sampling location from mouth in meters 
      spawning_state,  # alive, pink gill, grey gill, rotting (aka index of stream life)
      # pre_spawn,  # TRUE/FALSE (added in 2016); if the eggs and milt do not easily release and carcass has completely full gonads
      # partial_spawn,  # TRUE/FALSE (added in 2015); fish is sampled (dead or alive) with more than a little eggs or milt
      # preyed_upon,  # TRUE/FALSE (added in 2015); gonads removed by predators
      # stream_trib,  # stream tributary (Gilmour, Paddy, and Stockdale have multiple)
      # latitude,  # sampling area (where fish were moved to prior to sampling, rough approximate of spawning location)
      # longitude,  # sampling area (where fish were moved to prior to sampling, rough approximate of spawning location)
      otolith_mark_present,  # otolith mark present (yes = hatchery, no = natural)
      otolith_mark_id,  # otolith hatchery mark
      otolith_mark_status_code,  # otolith read status code (reason for no read = overground, lost, etc.)
      silly,  # GCL collection code
      fish_id,  # GCL fish ID within a silly
      dna_tray_code,  # 10-digit DWP barcode
      dna_tray_well_code,  # 48 DWP position 1:48
      # dna_tray_well_pos,  # 48 DWP position A1:H6
      # distance_tide,  # riverdist approximate sampling location from maximum high tide
      # riverdist_seg,  # riverdist river segment
      # riverdist_vert,  # riverdist vertex
      # riverdist_snapdist,  # riverdist snapping distance (aka how far was sampling location lat/long from the stream polyline)
      # high_tide  # highest extent of high tide in meters from mouth, unique to each stream
      fw_age,
      sw_age
    )  
)       
```

# Sample Sizes

Verify that all genotyped samples have metadata.
```{r}
geno_silly_source <- sapply(sillyvec, function(silly) {get(paste0(silly, ".gcl"))$SillySource}) %>% unlist()

table(geno_silly_source %in% metadata$silly_source)
```

Shoot, which samples do not have any metadata?

Ah, I bet they are the Fish Creek tag samples from 2013 that Tyler Dann and Heather Liller collected!
```{r}
setdiff(geno_silly_source, metadata$silly_source)
```

Correct. Add these to metadata.
```{r}
metadata <- 
  dplyr::bind_rows(metadata,
                   CMFISHCRT13.gcl %>% 
                     dplyr::select(SILLY_CODE, FK_FISH_ID, SillySource, DNA_TRAY_CODE, DNA_TRAY_WELL_CODE, CAPTURE_DATE) %>% 
                     dplyr::rename(silly = SILLY_CODE,
                                   fish_id = FK_FISH_ID,
                                   silly_source = SillySource, 
                                   dna_tray_code = DNA_TRAY_CODE,
                                   dna_tray_well_code = DNA_TRAY_WELL_CODE,
                                   date = CAPTURE_DATE) %>% 
                     tidyr::unite(col = "sample", dna_tray_code:dna_tray_well_code, sep = "_", remove = FALSE) %>% 
                     tidyr::unite(col = "silly_source", c(silly, fish_id), sep = "_", remove = FALSE) %>% 
                     dplyr::mutate(franz_id = stringr::str_c(stringr::str_sub(silly, 1, 2),  # 1st letter of species name, 1st letter of stream name
                                                             stringr::str_sub(silly, -2, -1),  # 2 digit sample year
                                                             "_",
                                                             stringr::str_pad(fish_id, width = 5, pad = "0", side = "left")),  # 5 digit fishid using padded zeros up front)
                                   date = lubridate::as_date(date),
                                   year = lubridate::year(date),
                                   stream = "Fish - Douglas Island",
                                   DOY = lubridate::yday(date)  # day of year
                     ) 
)
```

Verify all samples have metadata.
```{r}
table(geno_silly_source %in% metadata$silly_source)
```

Excellent, all present and accounted for.

Record which samples were genotyped.
```{r}
metadata <- metadata %>% 
  dplyr::mutate(genotyped = silly_source %in% geno_silly_source)
```

How many samples per collection (silly)?
```{r}
metadata %>% 
  dplyr::count(genotyped, silly) %>% 
  tidyr::pivot_wider(names_from = genotyped, values_from = n)
```

## Check For Sample Duplicates

I got a weird many-to-many error in a join the first time I ran through this script, so I want to check and see if there are actually duplicate samples present and if so, remove them!
```{r}
# bind all samples together into a single .gcl object
my.gcl <- sapply(sillyvec, function(silly) {
  my.silly <- get(paste0(silly, ".gcl"))
}, simplify = FALSE) %>% 
  dplyr::bind_rows()
```

Any duplicate `SillySource`?
```{r}
table(table(my.gcl$SillySource))
```

Clean up
```{r}
rm(my.gcl)
```

Are there metadata duplicates?
```{r}
table(table(metadata$silly_source))
```

Well son of a biscuit, there are!
```{r}
metadata %>% 
  dplyr::filter(duplicated(silly_source) | duplicated(silly_source, fromLast = TRUE)) %>% 
  dplyr::arrange(silly_source)
```

Okay, they appear to be true duplicates, no conflicting columns. Remove duplicate rows.
```{r}
metadata <- metadata %>% 
  dplyr::distinct(silly_source, .keep_all = TRUE)
```

## Join Metadata

Join `metadata` to each silly by `SillySource`.
```{r}
x <- sapply(sillyvec, function(silly) {
  my.silly <- get(paste0(silly, ".gcl"))
  my.silly <- my.silly %>% dplyr::left_join(
    y = metadata %>% dplyr::select(-genotyped),
    by = dplyr::join_by(SillySource == silly_source)
  )
  assign(x = paste0(silly, ".gcl"),
         value = my.silly,
         pos = 1)
})
rm(x)  # suppresses output
```

# Filter QC Crosscheck Plates

Create a vector of plate IDs to toss, pending QC crosschecks.
```{r}
plate_ids_qcxcheck <- c(64461, 64462, 64480, 64482, 64483, 64484, 64485, 64486, 64502, 64503, 64509, 64511, 64512, 64513, 64514, 64515, 64542, 64543, 64582, 56362, 56363) %>% as.character()
```

Get sample size by silly.
```{r}
(
  sample_size_qcxcheck <- dplyr::tibble(silly = sillyvec) %>%
    dplyr::mutate(genotyped = GCLr::silly_n(sillyvec = sillyvec) %>% dplyr::pull(n))
)
```

Remove any fish on the plates pending QC crosschecks.
```{r}
x <- sapply(sillyvec, function(silly) {
  my.silly <- get(paste0(silly, ".gcl"))
  my.silly <- my.silly %>% dplyr::filter(!stringr::str_detect(string = PLATE_ID, pattern = stringr::str_c(plate_ids_qcxcheck, collapse = "|")))
  assign(x = paste0(silly, ".gcl"),
         value = my.silly,
         pos = 1)
})
rm(x)  # suppresses output
```

How many fish were removed by silly?
```{r}
(
  sample_size_qcxcheck <- sample_size_qcxcheck %>%
    dplyr::mutate(qcxcheck = genotyped - GCLr::silly_n(sillyvec = sillyvec) %>% dplyr::pull(n))
)
```

How many total samples?
```{r}
sum(sample_size_qcxcheck$qcxcheck)
```

Okay, that looks about right for 21 plates. Must have been some partial plates.

# Genotype QA

Standard data QA (GT-seq, no `conScore`):

  * Remove fish missing genotypes (**<80%** loci)
  * Remove contamination (heterozygosity outliers **+/- 3.5** modified z-score)
  * Remove duplicates (**>95%** loci concordance, remove **both** duplicates)

```{r}
(
  sample_size_qa <- dplyr::tibble(silly = sillyvec) %>%
    dplyr::mutate(genotyped = GCLr::silly_n(sillyvec = sillyvec) %>% dplyr::pull(n))
)
```

## Missing Loci (<80%)

Remove fish with <80% loci genotyped.
```{r}
miss_loci <-
  GCLr::remove_ind_miss_loci(sillyvec = sillyvec,
                             proportion = 0.8)

# miss_loci$IDs_Removed

GCLr::save_objects(objects = "miss_loci", path =  "../objects", rds = TRUE)

(
  sample_size_qa <- sample_size_qa %>%
    dplyr::mutate(missing = genotyped - GCLr::silly_n(sillyvec = sillyvec) %>% dplyr::pull(n))
)
```

Overall `r format(sum(sample_size_qa$missing), big.mark = ",")` samples dropped due to poor quality DNA. 

What was genotyping success by spawning state?
```{r}
miss_loci_tib <- tibble::enframe(miss_loci$IDs_Removed, name = "silly", value = "fish_id") %>% 
  tidyr::unnest_longer(fish_id) %>% 
  dplyr::left_join(y = metadata, by = dplyr::join_by(silly, fish_id))

metadata %>% 
  dplyr::filter(genotyped) %>% 
  dplyr::mutate(drop_miss = silly_source %in% miss_loci_tib$silly_source) %>% 
  dplyr::count(drop_miss, spawning_state) %>% 
  tidyr::pivot_wider(names_from = drop_miss, values_from = n) %>% 
  dplyr::rename(n_drop = `TRUE`, n_keep = `FALSE`) %>% 
  dplyr::mutate(n = n_keep + n_drop,
                p_keep = n_keep / n,
                spawning_state = factor(spawning_state, levels = c("Alive", "Pink Gill", "Grey Gill", "Rotting"))) %>% 
  dplyr::arrange(spawning_state)
```

As expected, genotyping success was much lower for rotting fish.

## Contamination (Heterozygosity > +/- 3.5 modified Z-score)

Remove contaminated samples prior to checking for duplicates!

Individual heterozygosity outliers is our best metric for removing contaminated samples in the absence of something more sophisticated like *conScore* from [GTscore](https://github.com/gjmckinney/GTscore?tab=readme-ov-file#sample-summaries). In previous analyses, including [Shedd et al. 2022](https://doi.org/10.1111/eva.13356), we've used the standard 1.5 IQR outlier detection method to remove excessively heterozygous individuals. However, the 1.5 IQR method assumes a normal distribution, but heart sample heterozygosities tend to be skewed right due to contamination. As of 2024-02-08, we decided to pivot to using [modified Z-scores](https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm) with cutoffs of +/- 3.5 as recommended by Iglewicz and Hoaglin [^1]. The modified Z-score uses the median and median absolute deviation (MAD) instead of the mean and standard deviation, and is thus more robust to outliers and asymmetrical distributions.

[^1]: Boris Iglewicz and David Hoaglin (1993), "Volume 16: How to Detect and Handle Outliers", The ASQC Basic References in Quality Control: Statistical Techniques, Edward F. Mykytka, Ph.D., Editor. 

Source function and calculate individual heterozygosities from `AHRP-PWS-Pink-Salmon-Pedigrees` GitHub repo.
```{r}
source("~/GitHub_repos/AHRP-PWS-Pink-Salmon-Pedigrees/code/functions/calc_ind_het.R")

(
  ind_het <-
    calc_ind_het(
      sillyvec = sillyvec,
      loci = loci251,
      ncores = parallel::detectCores() - 4
    )
)
```

Calculate +/- 3.5 modified z-score cutoffs by *stream*. 
**NOTE** this means that the exact heterozygosity cutoff will vary slightly by stream. For PWS Pink Salmon, I did it separately by silly, but some of our sample sizes are pretty small here and we have the separate "tag" sillys. I'm opting to do this by stream to allow for subtle changes in allele frequency per stream.
```{r}
# Function to calculate median absolute deviation (MAD)
mad <- function(x) {
  median(abs(x - median(x)))
}

# Calculate the modified z-score for each individual
(
  ind_het <- ind_het %>%
    dplyr::mutate(
      year = 2000 + as.numeric(stringr::str_sub(
        string = silly,
        start = -2,
        end = -1
      )),
      stream = dplyr::case_when(
        stringr::str_detect(string = silly, pattern = "ADM") ~ "Admiralty",
        stringr::str_detect(string = silly, pattern = "FISH") ~ "Fish",
        stringr::str_detect(string = silly, pattern = "PROS") ~ "Prospect",
        stringr::str_detect(string = silly, pattern = "SAW") ~ "Sawmill",
        TRUE ~ "mistakes_were_made"
      )
    ) %>%
    dplyr::group_by(stream) %>%  # cutoffs are specific to each stream!
    dplyr::mutate(
      modified_z_score = 0.6745 * (het - median(het)) / mad(het),
      outlier = dplyr::case_when(abs(modified_z_score) > 3.5 ~ TRUE, TRUE ~ FALSE)
    ) %>%
    dplyr::ungroup()
)
  
GCLr::save_objects("ind_het", path = "objects", rds = TRUE)
```

Plot distribution of heterozygosity and show outliers.
```{r warning=FALSE, fig.height=10}
ind_het %>% 
  ggplot2::ggplot(ggplot2::aes(x = het, fill = outlier)) +
  ggplot2::geom_histogram(binwidth = 1 / length(loci251)) +
  ggplot2::facet_grid(rows = ggplot2::vars(stream), scales = "free_y") +
  ggplot2::xlim(0, 1) +
  ggplot2::scale_fill_manual(name = "Outlier", values = c("TRUE" = "black", "FALSE" = "grey60")) +
  ggplot2::xlab("Individual Heterozygosity") +
  ggplot2::ylab("Frequency") +
  ggplot2::ggtitle("Individual Heterozygosity - By Stream") +
  ggplot2::theme_bw(base_size = 14) 
```

Remove outliers.
```{r}
output <- lapply(sillyvec, function(x) {
  GCLr::remove_ids(
    silly = x,
    IDs = ind_het %>% dplyr::filter(outlier, silly == x) %>% dplyr::pull(fish_id)
  )
})

message(paste0("A total of ", ind_het %>% dplyr::filter(outlier) %>% nrow(), " individuals were removed from sillys in sillyvec."))
```

Not too many contaminated samples! Most likely culled during missing loci.
```{r}
(
  sample_size_qa <- sample_size_qa %>%
    dplyr::mutate(heterozygosity = genotyped - missing - GCLr::silly_n(sillyvec = sillyvec) %>% dplyr::pull(n))
)
```

Overall `r format(sum(sample_size_qa$heterozygosity), big.mark = ",")` samples dropped due to sample contamination. 

## Duplicate (>=95%)

Identify potential duplicate genotypes (>=95% loci).
```{r}
duplicate_check_95 <-
  GCLr::dupcheck_within_silly(
    sillyvec = sillyvec,
    minproportion = 0.95,
    minnonmissing = 0.6,
    ncores = parallel::detectCores() - 4
  )

GCLr::save_objects("duplicate_check_95", path = "objects", rds = TRUE)
```

How many duplicate pairs by silly?
```{r}
duplicate_check_95 %>% 
  dplyr::count(silly) %>% 
  dplyr::arrange(dplyr::desc(n))
```

Remove **both** duplicates! As opposed to GSI work, where we want to keep individuals but arenât typically worried about paired data, here we want to remove both individuals as the paired data integrity (including otolith reads!) is lost.
```{r}
duplicates_removed <-
  GCLr::remove_dups(dupcheck = duplicate_check_95, remove_both = TRUE)

GCLr::save_objects("duplicates_removed", path = "objects", rds = TRUE)

(
  sample_size_qa <- sample_size_qa %>%
    dplyr::mutate(
      duplicate = genotyped - missing - heterozygosity - GCLr::silly_n(sillyvec = sillyvec) %>% dplyr::pull(n)
    )
)
```

Overall `r format(sum(sample_size_qa$duplicate), big.mark = ",")` samples dropped due to duplicate genotypes. 

## Final

Final, post-QA sample sizes by silly.
```{r}
(
  sample_size_qa <- sample_size_qa %>%
    dplyr::mutate(
      final =  GCLr::silly_n(sillyvec = sillyvec) %>% dplyr::pull(n)
    )
)

GCLr::save_objects("sample_size_qa", path = "objects", rds = TRUE)

fs::dir_create("output")
readr::write_csv(x = sample_size_qa, file = "output/sample_size_qa.csv")
```

# Save

Save final genotypes and update metadata.

## Genotypes

Save post-QA genotypes with joined metadata.
```{r}
fs::dir_create("data/genotypes/postQA")
GCLr::save_sillys(sillyvec = sillyvec, path = "data/genotypes/postQA", rds = TRUE)
```

## Metadata

add `pass_QA`
```{r}
postQA_silly_source <- sapply(sillyvec, function(silly) {get(paste0(silly, ".gcl"))$SillySource}) %>% unlist()

metadata <- metadata %>% 
  dplyr::mutate(pass_QA = silly_source %in% postQA_silly_source)
```

Confirm.
```{r}
metadata %>% 
  dplyr::count(genotyped, pass_QA)
```

**NOTE** that `genotyped` in `sample_size_qa` doesn't match `genotyped` in `metadata` because I pre-filtered out QC Crosscheck plates.
```{r}
sample_size_qa %>% 
  janitor::adorn_totals() %>% 
  dplyr::filter(silly == "Total")
```

# QA Conclusions

Overall `r format(sum(metadata$genotyped), big.mark = ",")` total pedigree samples were genotyped; `r format(sum(metadata$genotyped) - sum(sample_size_qa$genotyped), big.mark = ",")` were removed due to pending QC Crosschecks; `r format(sum(sample_size_qa$missing), big.mark = ",")` were removed due to poor quality DNA (missing >= 20% loci); `r format(sum(sample_size_qa$heterozygosity), big.mark = ",")` were removed due to contaminated DNA (heterozygosity >= 3.5 modified z-score); and `r format(sum(sample_size_qa$duplicate), big.mark = ",")` were removed due to duplicate genotypes (>= 95% loci), leaving a total of **`r format(sum(sample_size_qa$final), big.mark = ",")`** in the final dataset.

# Adaptive Loci Genotypes

Create a single object with just the metadata and adaptive loci genotypes.
```{r}
(
  chum_adaptive_geno <- sapply(sillyvec, function(silly) {
    get(paste0(silly, ".gcl"))
  }, simplify = FALSE) %>%
    dplyr::bind_rows() %>%
    dplyr::select(
      silly_source = SillySource,
      plate_id = PLATE_ID,
      stream:sw_age,
      dplyr::contains("OkeV2")
    )
)
```

## Calculate Allele Frequencies

Calculate the allele counts for each locus by stream, year, and DOY.
Adapted from Pat Barry's code in `AHRP_ChumAdaptive.html`
```{r}
loci_adaptive <- grep(pattern = "OkeV2", x = loci251, value = TRUE)

# testing
# chum_adaptive_geno %>%
#   dplyr::select(silly_source, stream, year, DOY, tidyselect::starts_with(loci_adaptive[1])) %>%
#   tidyr::pivot_longer(cols = tidyselect::starts_with(loci_adaptive[1]), names_to = "locus", values_to = "allele") %>%
#   dplyr::mutate(allele = factor(allele),
#                 allele = as.numeric(allele)) %>%  # make factor and convert to numeric
#   dplyr::count(stream, year, DOY, allele) %>%
#   dplyr::mutate(locus = loci_adaptive[1])

# calculate the number of each allele observed per stream, year, day
(chum_adaptive_allele_counts <- lapply(loci_adaptive, function(locus) {
  chum_adaptive_geno %>%
    dplyr::select(silly_source,
                  stream,
                  year,
                  DOY,
                  tidyselect::starts_with(locus)) %>%
    tidyr::pivot_longer(
      cols = tidyselect::starts_with(locus),
      names_to = "locus",
      values_to = "allele"
    ) %>%
    dplyr::mutate(allele = factor(allele),
                allele = as.numeric(allele)) %>%  # make factor and convert to numeric
    dplyr::count(stream, year, DOY, allele) %>%
    dplyr::mutate(locus = locus)
}) %>%
    dplyr::bind_rows())
```

Convert to alelle frequencies.
```{r}
(
  chum_adaptive_allele_freq <- chum_adaptive_allele_counts %>%
    tidyr::pivot_wider(names_from = allele, values_from = n) %>%
    dplyr::select(-`NA`) %>%  # drop no-calls
    dplyr::mutate(
      `1` = replace_na(`1`, 0),
      # account for unobserved alleles on a given day
      `2` = replace_na(`2`, 0)
    ) %>%
    tidyr::pivot_longer(
      cols = `1`:`2`,
      names_to = "allele",
      values_to = "n"
    ) %>%
    dplyr::group_by(stream, year, DOY, locus) %>%
    dplyr::mutate(
      n_alleles = sum(n),
      p_alleles = n / n_alleles,
      SNP = paste(locus, allele, sep = "_")
    ) %>% 
    dplyr::ungroup()
)
```

## View Allele Frequencies

```{r}
#  TODO
# double check allele frequency code to make sure it is correct
# make sure alleles are being assigned 1 vs. 2 consistently
# filter out hatchery strays?
# check sample sizes by stream/year/DOY?
# see if spawning state correlates?
```

### Admiralty

```{r fig.height=10}
chum_adaptive_allele_freq %>% 
  dplyr::filter(stream == "Admiralty") %>% 
  dplyr::mutate(locus = stringr::str_remove_all(string = locus, pattern = "OkeV2_")) %>% 
  ggplot2::ggplot(ggplot2::aes(x = DOY, y = p_alleles, colour = SNP, group_by(SNP))) +
  ggplot2::geom_point() +
  ggplot2::geom_smooth(method = "lm", weight = "n_alleles", formula = y~x) +
  ggplot2::facet_grid(locus ~ year) + 
  ggplot2::theme_bw() + 
  ggplot2::theme(legend.position = 'none')
```

### Fish

```{r fig.height=10}
chum_adaptive_allele_freq %>% 
  dplyr::filter(stream == "Fish - Douglas Island") %>% 
  dplyr::mutate(locus = stringr::str_remove_all(string = locus, pattern = "OkeV2_")) %>% 
  ggplot2::ggplot(ggplot2::aes(x = DOY, y = p_alleles, colour = SNP, group_by(SNP))) +
  ggplot2::geom_point() +
  ggplot2::geom_smooth(method = "lm", weight = "n_alleles", formula = y~x) +
  ggplot2::facet_grid(locus ~ year) + 
  ggplot2::theme_bw() + 
  ggplot2::theme(legend.position = 'none')
```

### Prospect

```{r fig.height=10}
chum_adaptive_allele_freq %>% 
  dplyr::filter(stream == "Prospect") %>% 
  dplyr::mutate(locus = stringr::str_remove_all(string = locus, pattern = "OkeV2_")) %>% 
  ggplot2::ggplot(ggplot2::aes(x = DOY, y = p_alleles, colour = SNP, group_by(SNP))) +
  ggplot2::geom_point() +
  ggplot2::geom_smooth(method = "lm", weight = "n_alleles", formula = y~x) +
  ggplot2::facet_grid(locus ~ year) + 
  ggplot2::theme_bw() + 
  ggplot2::theme(legend.position = 'none')
```

### Sawmill

```{r fig.height=10}
chum_adaptive_allele_freq %>% 
  dplyr::filter(stream == "Sawmill") %>% 
  dplyr::mutate(locus = stringr::str_remove_all(string = locus, pattern = "OkeV2_")) %>% 
  ggplot2::ggplot(ggplot2::aes(x = DOY, y = p_alleles, colour = SNP, group_by(SNP))) +
  ggplot2::geom_point() +
  ggplot2::geom_smooth(method = "lm", weight = "n_alleles", formula = y~x) +
  ggplot2::facet_grid(locus ~ year) + 
  ggplot2::theme_bw() + 
  ggplot2::theme(legend.position = 'none')
```

end